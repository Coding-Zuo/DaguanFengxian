{
  "gpu": {
    "use": true,
    "id": "2",
    "local_rank": -1,
    "data_parallel": false
  },
  "general": {
    "do_train": true,
    "do_eval": true,
    "fp16": true,
    "fp16_opt_level": "O1",
    "exp_name": "train.bert_large_v2_wsample",
    "task": "daguan",
    "model_type": "bert_large",
    "model_encoder_type": "bert",
    "vocab_mapping": true,
    "main_data_dir": "/data2/code/DaguanFengxian/bert_model/data/",
    "data_dir": "splits/fold_0_bert_large_vocab",
    "label_file_level_1": "labels_level_1.txt",
    "label_file_level_2": "labels_level_2.txt",
    "label2freq_level_1": "label2freq_level_1.json",
    "label2freq_level_2": "label2freq_level_2.json",
    "encoder_name_or_path": "/data2/pre-model/bert/bert_large_chinese"
  },
  "params": {
    "seed": 1234,
    "max_time": 24,
    "metric_key_for_early_stop": "macro avg__f1-score__level_2",
    "logging_steps": 200,
    "save_steps": 200,
    "max_steps": -1,
    "patience": 12,
    "print_epoch_interval": 5,
    "lr": {
      "init_lr": 0.0005,
      "linear_lr": 5e-4,
      "encoder_learning_rate": 0.5e-4,
      "min_lr": 1e-6,
      "embeddings_learning_rate": 0.5e-4
    },
    "schedule": {
      "weight_decay": 0.0,
      "warmup_steps": 200,
      "max_grad_norm": 1.0,
      "num_train_epochs": 50,
      "per_gpu_train_batch_size": 16,
      "gradient_accumulation_steps": 2,
      "eval_batch_size": 32
    },
    "loss": {
      "use_focal_loss": true,
      "focal_loss_gamma": 2.0,
      "use_class_weights": true,
      "use_weighted_sampler": true
    }
  },
  "net_params": {
    "hidden_dim": 768,
    "use_lstm": true,
    "aggregator": "bert_pooler",
    "dropout": 0.15,
    "use_fgm": false,
    "use_pgd": false
  },
  "encoder_params": {
    "max_seq_len": 133,
    "do_lower_case": true
  }
}
